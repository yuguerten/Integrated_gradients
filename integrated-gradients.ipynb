{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-14T09:47:02.245841Z","iopub.execute_input":"2024-07-14T09:47:02.246386Z","iopub.status.idle":"2024-07-14T09:47:02.253672Z","shell.execute_reply.started":"2024-07-14T09:47:02.246347Z","shell.execute_reply":"2024-07-14T09:47:02.252516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install captum","metadata":{"execution":{"iopub.status.busy":"2024-07-14T09:47:03.144032Z","iopub.execute_input":"2024-07-14T09:47:03.144412Z","iopub.status.idle":"2024-07-14T09:47:17.871915Z","shell.execute_reply.started":"2024-07-14T09:47:03.144383Z","shell.execute_reply":"2024-07-14T09:47:17.870196Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting captum\n  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from captum) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum) (1.26.4)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum) (2.1.2+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from captum) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (2024.3.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\nDownloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: captum\nSuccessfully installed captum-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-14T09:47:17.874510Z","iopub.execute_input":"2024-07-14T09:47:17.874894Z","iopub.status.idle":"2024-07-14T09:47:30.505836Z","shell.execute_reply.started":"2024-07-14T09:47:17.874856Z","shell.execute_reply":"2024-07-14T09:47:30.504265Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom captum.attr import LayerIntegratedGradients\nfrom captum.attr import visualization as viz","metadata":{"execution":{"iopub.status.busy":"2024-07-14T09:47:30.507907Z","iopub.execute_input":"2024-07-14T09:47:30.508848Z","iopub.status.idle":"2024-07-14T09:47:34.880156Z","shell.execute_reply.started":"2024-07-14T09:47:30.508792Z","shell.execute_reply":"2024-07-14T09:47:34.879071Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model_name = 'CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T10:19:13.505688Z","iopub.execute_input":"2024-07-14T10:19:13.506121Z","iopub.status.idle":"2024-07-14T10:19:38.843515Z","shell.execute_reply.started":"2024-07-14T10:19:13.506091Z","shell.execute_reply":"2024-07-14T10:19:38.842102Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6dab0d81a644d4ace9abb071d57993"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87f2edcb4144d93b677b1e7285022e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/305k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900081590ef4488284add49f82cb8d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c6daaa2088948be99a81549d8b42227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fb68b30880f43bbb5c8a837ca8d5099"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Construct Original and Baseline Input","metadata":{}},{"cell_type":"code","source":"def construct_input_and_baseline(text):\n\n    max_length = 510\n    baseline_token_id = tokenizer.pad_token_id \n    sep_token_id = tokenizer.sep_token_id \n    cls_token_id = tokenizer.cls_token_id \n\n    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n   \n    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n  \n\n    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list","metadata":{"execution":{"iopub.status.busy":"2024-07-14T10:20:08.601879Z","iopub.execute_input":"2024-07-14T10:20:08.602276Z","iopub.status.idle":"2024-07-14T10:20:08.609287Z","shell.execute_reply.started":"2024-07-14T10:20:08.602242Z","shell.execute_reply":"2024-07-14T10:20:08.608212Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Define Model Input and Output","metadata":{}},{"cell_type":"code","source":"# Define model output\ndef model_output(inputs):\n    return model(inputs)[0]\n\n# Define model input\nmodel_input = model.bert.embeddings","metadata":{"execution":{"iopub.status.busy":"2024-07-14T10:20:16.412829Z","iopub.execute_input":"2024-07-14T10:20:16.413256Z","iopub.status.idle":"2024-07-14T10:20:16.418960Z","shell.execute_reply.started":"2024-07-14T10:20:16.413223Z","shell.execute_reply":"2024-07-14T10:20:16.417553Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Instantiate Integrated Gradients Method","metadata":{}},{"cell_type":"code","source":"lig = LayerIntegratedGradients(model_output, model_input)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T10:20:20.810765Z","iopub.execute_input":"2024-07-14T10:20:20.811185Z","iopub.status.idle":"2024-07-14T10:20:20.816579Z","shell.execute_reply.started":"2024-07-14T10:20:20.811156Z","shell.execute_reply":"2024-07-14T10:20:20.815550Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"text = 'لم أحب الطعام الذي تناولته بالأمس' # true negative\ninput_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\nprint(f'original text: {input_ids}')\nprint(f'baseline text: {baseline_input_ids}')","metadata":{"execution":{"iopub.status.busy":"2024-07-14T11:53:28.702290Z","iopub.execute_input":"2024-07-14T11:53:28.702748Z","iopub.status.idle":"2024-07-14T11:53:28.712015Z","shell.execute_reply.started":"2024-07-14T11:53:28.702713Z","shell.execute_reply":"2024-07-14T11:53:28.710957Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"original text: tensor([[    2,  2043,  7699,  6437,  2130, 22578,  1028,  3876,  2632,     3]])\nbaseline text: tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 3]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Compute Attributions","metadata":{}},{"cell_type":"code","source":"attributions, delta = lig.attribute(input_ids, baseline_input_ids, target=true_class, return_convergence_delta=True )\nprint(attributions.size())","metadata":{"execution":{"iopub.status.busy":"2024-07-14T11:53:29.855660Z","iopub.execute_input":"2024-07-14T11:53:29.856052Z","iopub.status.idle":"2024-07-14T11:53:31.429028Z","shell.execute_reply.started":"2024-07-14T11:53:29.856020Z","shell.execute_reply":"2024-07-14T11:53:31.427883Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"torch.Size([1, 10, 768])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Compute Attribution for Each Token","metadata":{}},{"cell_type":"code","source":"def summarize_attributions(attributions):\n\n    attributions = attributions.sum(dim=-1).squeeze(0)\n    attributions = attributions / torch.norm(attributions)\n    \n    return attributions\n\nattributions_sum = summarize_attributions(attributions)\nprint(attributions_sum.size())","metadata":{"execution":{"iopub.status.busy":"2024-07-14T11:53:31.431129Z","iopub.execute_input":"2024-07-14T11:53:31.431584Z","iopub.status.idle":"2024-07-14T11:53:31.440140Z","shell.execute_reply.started":"2024-07-14T11:53:31.431543Z","shell.execute_reply":"2024-07-14T11:53:31.438954Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"torch.Size([10])\n","output_type":"stream"}]},{"cell_type":"code","source":"# 0: Negative, 1: Neutral, 2: Positive \nscore_vis = viz.VisualizationDataRecord(\n                        word_attributions = attributions_sum,\n                        pred_prob = torch.max(model(input_ids)[0]),\n                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n                        true_class = 0,\n                        attr_class = text,\n                        attr_score = attributions_sum.sum(),       \n                        raw_input_ids = all_tokens,\n                        convergence_score = delta)\n\nviz.visualize_text([score_vis])","metadata":{"execution":{"iopub.status.busy":"2024-07-14T11:53:41.133278Z","iopub.execute_input":"2024-07-14T11:53:41.134366Z","iopub.status.idle":"2024-07-14T11:53:41.269104Z","shell.execute_reply.started":"2024-07-14T11:53:41.134324Z","shell.execute_reply":"2024-07-14T11:53:41.267839Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.84)</b></text></td><td><text style=\"padding-right:2em\"><b>لم أحب الطعام الذي تناولته بالأمس</b></text></td><td><text style=\"padding-right:2em\"><b>0.62</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> لم                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> أحب                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> الطعام                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> الذي                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> تناولت                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ه                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> بالأ                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##مس                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"},"metadata":{}},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.84)</b></text></td><td><text style=\"padding-right:2em\"><b>لم أحب الطعام الذي تناولته بالأمس</b></text></td><td><text style=\"padding-right:2em\"><b>0.62</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> لم                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> أحب                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> الطعام                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> الذي                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> تناولت                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ه                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> بالأ                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##مس                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}